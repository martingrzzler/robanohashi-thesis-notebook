{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers datasets -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset json (/root/.cache/huggingface/datasets/martingrzzler___json/martingrzzler--conreteness_ratings-8e85e116392013eb/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de5aa3c7c54741169b149547d430cbb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset('martingrzzler/conreteness_ratings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Word': Value(dtype='string', id=None),\n",
       " 'Bigram': Value(dtype='int64', id=None),\n",
       " 'Conc.M': Value(dtype='float64', id=None),\n",
       " 'Conc.SD': Value(dtype='float64', id=None),\n",
       " 'Unknown': Value(dtype='int64', id=None),\n",
       " 'Total': Value(dtype='int64', id=None),\n",
       " 'Percent_known': Value(dtype='float64', id=None),\n",
       " 'SUBTLEX': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.rename_column('Conc.M', 'avg_concreteness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Word': 'absorbable',\n",
       " 'Bigram': 0,\n",
       " 'avg_concreteness': 2.47,\n",
       " 'Conc.SD': 1.36,\n",
       " 'Unknown': 0,\n",
       " 'Total': 30,\n",
       " 'Percent_known': 1.0,\n",
       " 'SUBTLEX': 0}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datasets import Dataset \n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "processing_ds = ds['train'].to_pandas()\n",
    "\n",
    "processing_ds['avg_concreteness'] = scaler.fit_transform(processing_ds['avg_concreteness'].to_numpy().reshape(-1, 1))\n",
    "\n",
    "ds['train'] = Dataset.from_pandas(processing_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(ds['train']['avg_concreteness']).max(), np.array(ds['train']['avg_concreteness']).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds['train'].to_pandas()['avg_concreteness'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    39954.000000\n",
       "mean         0.504108\n",
       "std          0.262273\n",
       "min          0.000000\n",
       "25%          0.272727\n",
       "50%          0.464646\n",
       "75%          0.719697\n",
       "max          1.000000\n",
       "Name: avg_concreteness, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'].to_pandas()['avg_concreteness'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.remove_columns(['Conc.SD', 'Unknown', 'Total', 'SUBTLEX', 'Percent_known', 'Bigram'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize(batch):\n",
    "    # max_length as suggested by the paper\n",
    "    return tokenizer(batch['Word'], padding='max_length', truncation=True, max_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96cdd18762784f0bbb41f15a2f0f4e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/39954 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = ds.filter(lambda x: x['Word'] is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89fd7aeb6d97400e8ee589228075b148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/39953 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_ds = ds.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_ds = tokenized_ds.rename_column('avg_concreteness', 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_ds = tokenized_ds['train'].train_test_split(test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_ds.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(tokenized_ds['train'], batch_size=8)\n",
    "test_loader = DataLoader(tokenized_ds['test'], batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "# suggested learning rate by the paper\n",
    "optimizer = Adam(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 3\n",
    "num_training_steps = len(train_loader) * 3\n",
    "\n",
    "lr_scheduler = get_scheduler(name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56be64718902470b9da7ea860c624abc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13485 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation Coefficient: 0.9205\n",
      "P-value: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "targets = []\n",
    "\n",
    "for batch in test_loader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "    logits = outputs.logits\n",
    "    predictions.extend(logits.squeeze().tolist())\n",
    "    targets.extend(batch[\"labels\"].squeeze().tolist())\n",
    "\n",
    "\n",
    "\n",
    "corr_corf, p_value = pearsonr(predictions, targets)\n",
    "\n",
    "print(f\"Pearson Correlation Coefficient: {corr_corf:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(word):\n",
    "    input_ids = tokenizer(word, return_tensors='pt').input_ids.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "    logits = outputs.logits\n",
    "    return logits.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1439209133386612, 0.299909770488739, 0.9963857531547546, 1.0014569759368896)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('abstract'), predict('novelty'), predict('dog'), predict('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('word_concreteness_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid.\n",
      "Your token has been saved in your configured git credential helpers (store).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/martingrzzler/bert-word-conreteness/commit/8484a9db5460e3c3d2c6beda5d6152f7ae3f11a9', commit_message='Upload BertForSequenceClassification', commit_description='', oid='8484a9db5460e3c3d2c6beda5d6152f7ae3f11a9', pr_url='https://huggingface.co/martingrzzler/bert-word-conreteness/discussions/1', pr_revision='refs/pr/1', pr_num=1)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub('martingrzzler/bert-word-conreteness', create_pr=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

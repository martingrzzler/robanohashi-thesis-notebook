{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.3/269.3 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "%pip install datasets -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d07fa3cbdba4279a61548cadce37155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/131 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/martingrzzler--mnemonics_benchmark to /root/.cache/huggingface/datasets/martingrzzler___json/martingrzzler--mnemonics_benchmark-6cc75b71b93e3c15/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b41070d300d94edabeb897dce089e70a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c105749c33a45cf96c3dc0bc9fdc17d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/274k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b09f94b4e99645bf9dac70e95482af39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04227ea0bed5458c86ce5bf89ff0bb32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/martingrzzler___json/martingrzzler--mnemonics_benchmark-6cc75b71b93e3c15/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99a2f6c0d12c4507a513d895a15c10c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"martingrzzler/mnemonics_benchmark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "character_message = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"\"\"\n",
    "You are a human that rank orders mnemonics. The mnemonics have been constructed to help students learn Japanese Kanji and are based on its component meanings such that the Kanji meaning can be recalled easily. You are given four different mnemonics and you have to order them from most memorable to least memorable.\n",
    "Output the ordered numbers separated by commas. E.g. 4,2,1,3\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "keys = ['gpt2xl_mnemonic', 'gpt3_mnemonic', 'gpt3_paragraph', 'wanikani_mnemonic']\n",
    "\n",
    "def get_user_message(example):\n",
    "    msg = f\"Component meanings: {example['component_meanings']}\\nKanji meaning: {example['kanji_meaning']}\\n\"\n",
    "    msg += \"Mnemonics:\\n\"\n",
    "    for i, key in enumerate(keys):\n",
    "        text = re.sub(r'<.*?>', '', example[key])\n",
    "        msg += f\"[{i+1}] {text}\\n\"\n",
    "    \n",
    "    return {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": msg\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Component meanings: woman,catapult\\nKanji meaning: recreation\\nMnemonics:\\n[1] This is a rush transcript. Copy may not be in its final form, recreation of woman being catapulted to her death has been edited out.)\\n\\n\\nAMY GOODMAN: We begin today's show with the shocking news that two women have died after jumping from an overpass near Los Angeles International Airport and landing on I-5 southbound just before\\n[2] Once upon a time there was a woman who wanted to recreate her childhood memories of playing with a catapult. She went to the local store to buy one, but instead she found a cute little white cat that she just couldn't resist. She decided to take the cat home and name him Catapult. From then on, the woman and Catapult would have fun together playing games and recreating her childhood memories.\\n[3] A woman was using a catapult for recreation in her backyard. She was having a blast launching objects into the air and watching them fly. She was enjoying the peacefulness of the moment and the satisfaction of her successful shots.\\n[4] A woman loves her catapult for some good ol' fashioned recreation. You ask the woman what she does for fun... for recreation. She says, she goes out and shoots her catapult.\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_user_message(ds['train'][0])['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "res = openai.ChatCompletion.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[character_message, get_user_message(ds['train'][10])],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def map_rank(example):\n",
    "    res = openai.ChatCompletion.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=[character_message, get_user_message(example)],\n",
    "    )\n",
    "    example['model_answer'] = res['choices'][0]['message']['content']\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a9be1f4f1142b9a7050d9004459a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/190 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_model_ranks = ds['train'].map(map_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d01660f8274413adefd3b20fdd4c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "281554"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_model_ranks.to_json('ds_model_ranks.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyids = [1,2,3,4]\n",
    "\n",
    "\n",
    "def parse_ranks(example):\n",
    "    try:\n",
    "        parsed = example['model_answer'][:11].replace('.','').split(',')\n",
    "        parsed = [int(x) for x in parsed]\n",
    "        ranks = []\n",
    "        for id in keyids:\n",
    "            ranks.append(parsed.index(id) + 1)\n",
    "            \n",
    "        example['model_ranks'] = ranks\n",
    "\n",
    "    except:\n",
    "        example['model_ranks'] = None\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "mranks = [2,3,4,1]\n",
    "ids = [1,2,3,4]\n",
    "\n",
    "for id in ids:\n",
    "    print(mranks.index(id) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/martingrzzler___json/martingrzzler--mnemonics_benchmark-6cc75b71b93e3c15/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-e108a054bdfa10c9.arrow\n"
     ]
    }
   ],
   "source": [
    "ds_ranks = ds_model_ranks.map(parse_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 1, 2, 3],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [2, 1, 3, 4],\n",
       " [3, 1, 2, 4],\n",
       " [2, 1, 4, 3],\n",
       " [2, 1, 4, 3],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 2, 4],\n",
       " [3, 1, 4, 2],\n",
       " [4, 1, 3, 2],\n",
       " [3, 1, 2, 4],\n",
       " [3, 1, 4, 2],\n",
       " [4, 1, 3, 2],\n",
       " [3, 1, 2, 4],\n",
       " [3, 1, 4, 2],\n",
       " [2, 1, 3, 4],\n",
       " [3, 1, 2, 4],\n",
       " [3, 1, 4, 2],\n",
       " [2, 1, 3, 4],\n",
       " [3, 1, 2, 4],\n",
       " [4, 1, 2, 3],\n",
       " [4, 1, 2, 3],\n",
       " [4, 1, 3, 2],\n",
       " [2, 1, 3, 4],\n",
       " [3, 2, 4, 1],\n",
       " [4, 1, 3, 2],\n",
       " [2, 1, 3, 4],\n",
       " [4, 1, 3, 2],\n",
       " [3, 1, 2, 4],\n",
       " [2, 1, 3, 4],\n",
       " [4, 1, 2, 3],\n",
       " [2, 1, 3, 4],\n",
       " [4, 1, 2, 3],\n",
       " [2, 1, 3, 4],\n",
       " [2, 1, 4, 3],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [4, 1, 2, 3],\n",
       " [4, 1, 3, 2],\n",
       " [2, 1, 3, 4],\n",
       " [4, 1, 3, 2],\n",
       " [4, 1, 3, 2],\n",
       " [4, 1, 3, 2],\n",
       " [2, 1, 4, 3],\n",
       " [4, 1, 2, 3],\n",
       " [2, 1, 4, 3],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [4, 1, 2, 3],\n",
       " [3, 1, 2, 4],\n",
       " [4, 1, 3, 2],\n",
       " [4, 1, 2, 3],\n",
       " [4, 1, 2, 3],\n",
       " [4, 1, 3, 2],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [2, 1, 4, 3],\n",
       " [2, 1, 3, 4],\n",
       " [4, 1, 3, 2],\n",
       " [3, 1, 4, 2],\n",
       " [4, 1, 3, 2],\n",
       " [2, 1, 3, 4],\n",
       " [2, 1, 3, 4],\n",
       " [4, 1, 3, 2],\n",
       " [4, 1, 3, 2],\n",
       " [4, 1, 2, 3],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [2, 1, 4, 3],\n",
       " [3, 1, 2, 4],\n",
       " [3, 1, 4, 2],\n",
       " [4, 1, 3, 2],\n",
       " [2, 1, 3, 4],\n",
       " [4, 1, 3, 2],\n",
       " [2, 1, 3, 4],\n",
       " [3, 1, 4, 2],\n",
       " [2, 1, 4, 3],\n",
       " [2, 1, 3, 4],\n",
       " [3, 1, 4, 2],\n",
       " [2, 1, 3, 4],\n",
       " [2, 1, 3, 4],\n",
       " [4, 1, 3, 2],\n",
       " [3, 1, 4, 2],\n",
       " [4, 1, 2, 3],\n",
       " [3, 1, 4, 2],\n",
       " [2, 1, 3, 4],\n",
       " [3, 1, 2, 4],\n",
       " [3, 1, 2, 4],\n",
       " [4, 1, 2, 3],\n",
       " [3, 1, 2, 4],\n",
       " [3, 1, 2, 4],\n",
       " [2, 1, 3, 4],\n",
       " [3, 1, 2, 4],\n",
       " [4, 1, 3, 2],\n",
       " [2, 1, 4, 3],\n",
       " [4, 1, 2, 3],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [4, 1, 2, 3],\n",
       " [4, 1, 3, 2],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [4, 1, 2, 3],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " None,\n",
       " [4, 1, 3, 2],\n",
       " [4, 1, 2, 3],\n",
       " [3, 1, 2, 4],\n",
       " None,\n",
       " [3, 1, 4, 2],\n",
       " [2, 1, 3, 4],\n",
       " [3, 1, 2, 4],\n",
       " [2, 1, 4, 3],\n",
       " [2, 1, 4, 3],\n",
       " [4, 1, 3, 2],\n",
       " [3, 1, 4, 2],\n",
       " [4, 1, 2, 3],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 2, 4],\n",
       " [2, 1, 4, 3],\n",
       " [2, 1, 3, 4],\n",
       " [3, 1, 4, 2],\n",
       " [4, 1, 2, 3],\n",
       " [4, 1, 2, 3],\n",
       " [4, 1, 2, 3],\n",
       " [3, 1, 4, 2],\n",
       " [2, 1, 4, 3],\n",
       " [3, 1, 2, 4],\n",
       " [4, 1, 2, 3],\n",
       " [2, 1, 3, 4],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 2, 4],\n",
       " [4, 1, 2, 3],\n",
       " [3, 1, 4, 2],\n",
       " [4, 1, 2, 3],\n",
       " [2, 1, 3, 4],\n",
       " [4, 1, 3, 2],\n",
       " [2, 1, 3, 4],\n",
       " [2, 1, 3, 4],\n",
       " [2, 1, 4, 3],\n",
       " [4, 1, 2, 3],\n",
       " [4, 1, 2, 3],\n",
       " [3, 1, 2, 4],\n",
       " [2, 1, 3, 4],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 2, 4],\n",
       " [2, 1, 4, 3],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 2, 4],\n",
       " [2, 1, 4, 3],\n",
       " [2, 1, 3, 4],\n",
       " [4, 1, 3, 2],\n",
       " [4, 1, 2, 3],\n",
       " [2, 1, 3, 4],\n",
       " [2, 1, 4, 3],\n",
       " [3, 1, 4, 2],\n",
       " [4, 1, 3, 2],\n",
       " [2, 1, 3, 4],\n",
       " [2, 1, 3, 4],\n",
       " [4, 1, 3, 2],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [4, 1, 3, 2],\n",
       " [3, 1, 2, 4],\n",
       " [3, 1, 4, 2],\n",
       " [4, 1, 3, 2],\n",
       " [2, 1, 4, 3],\n",
       " [3, 1, 2, 4],\n",
       " [2, 1, 3, 4],\n",
       " [2, 1, 3, 4],\n",
       " [4, 1, 3, 2],\n",
       " [2, 1, 4, 3],\n",
       " [2, 1, 3, 4],\n",
       " [4, 1, 2, 3],\n",
       " [3, 1, 4, 2]]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_ranks['model_ranks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ab529b7b0c040a683ffc3f964685ca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/190 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_ranks_filtered = ds_ranks.filter(lambda x: x['model_ranks'] is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['kanji_id', 'component_meanings', 'wanikani_mnemonic', 'kanji_meaning', 'gpt2xl_mnemonic', 'gpt3_paragraph', 'gpt3_mnemonic', 'model_answer', 'model_ranks'],\n",
       "    num_rows: 188\n",
       "})"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_ranks_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 1, 2, 3],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [2, 1, 3, 4],\n",
       " [3, 1, 2, 4],\n",
       " [2, 1, 4, 3],\n",
       " [2, 1, 4, 3],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 2, 4],\n",
       " [3, 1, 4, 2],\n",
       " [4, 1, 3, 2],\n",
       " [3, 1, 2, 4],\n",
       " [3, 1, 4, 2],\n",
       " [4, 1, 3, 2],\n",
       " [3, 1, 2, 4],\n",
       " [3, 1, 4, 2],\n",
       " [2, 1, 3, 4],\n",
       " [3, 1, 2, 4],\n",
       " [3, 1, 4, 2],\n",
       " [2, 1, 3, 4],\n",
       " [3, 1, 2, 4],\n",
       " [4, 1, 2, 3],\n",
       " [4, 1, 2, 3],\n",
       " [4, 1, 3, 2],\n",
       " [2, 1, 3, 4],\n",
       " [3, 2, 4, 1],\n",
       " [4, 1, 3, 2],\n",
       " [2, 1, 3, 4],\n",
       " [4, 1, 3, 2],\n",
       " [3, 1, 2, 4],\n",
       " [2, 1, 3, 4],\n",
       " [4, 1, 2, 3],\n",
       " [2, 1, 3, 4],\n",
       " [4, 1, 2, 3],\n",
       " [2, 1, 3, 4],\n",
       " [2, 1, 4, 3],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [4, 1, 2, 3],\n",
       " [4, 1, 3, 2],\n",
       " [2, 1, 3, 4],\n",
       " [4, 1, 3, 2],\n",
       " [4, 1, 3, 2],\n",
       " [4, 1, 3, 2],\n",
       " [2, 1, 4, 3],\n",
       " [4, 1, 2, 3],\n",
       " [2, 1, 4, 3],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [4, 1, 2, 3],\n",
       " [3, 1, 2, 4],\n",
       " [4, 1, 3, 2],\n",
       " [4, 1, 2, 3],\n",
       " [4, 1, 2, 3],\n",
       " [4, 1, 3, 2],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [2, 1, 4, 3],\n",
       " [2, 1, 3, 4],\n",
       " [4, 1, 3, 2],\n",
       " [3, 1, 4, 2],\n",
       " [4, 1, 3, 2],\n",
       " [2, 1, 3, 4],\n",
       " [2, 1, 3, 4],\n",
       " [4, 1, 3, 2],\n",
       " [4, 1, 3, 2],\n",
       " [4, 1, 2, 3],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [2, 1, 4, 3],\n",
       " [3, 1, 2, 4],\n",
       " [3, 1, 4, 2],\n",
       " [4, 1, 3, 2],\n",
       " [2, 1, 3, 4],\n",
       " [4, 1, 3, 2],\n",
       " [2, 1, 3, 4],\n",
       " [3, 1, 4, 2],\n",
       " [2, 1, 4, 3],\n",
       " [2, 1, 3, 4],\n",
       " [3, 1, 4, 2],\n",
       " [2, 1, 3, 4],\n",
       " [2, 1, 3, 4],\n",
       " [4, 1, 3, 2],\n",
       " [3, 1, 4, 2],\n",
       " [4, 1, 2, 3],\n",
       " [3, 1, 4, 2],\n",
       " [2, 1, 3, 4],\n",
       " [3, 1, 2, 4],\n",
       " [3, 1, 2, 4],\n",
       " [4, 1, 2, 3],\n",
       " [3, 1, 2, 4],\n",
       " [3, 1, 2, 4],\n",
       " [2, 1, 3, 4],\n",
       " [3, 1, 2, 4],\n",
       " [4, 1, 3, 2],\n",
       " [2, 1, 4, 3],\n",
       " [4, 1, 2, 3],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [4, 1, 2, 3],\n",
       " [4, 1, 3, 2],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [4, 1, 2, 3],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [4, 1, 3, 2],\n",
       " [4, 1, 2, 3],\n",
       " [3, 1, 2, 4],\n",
       " [3, 1, 4, 2],\n",
       " [2, 1, 3, 4],\n",
       " [3, 1, 2, 4],\n",
       " [2, 1, 4, 3],\n",
       " [2, 1, 4, 3],\n",
       " [4, 1, 3, 2],\n",
       " [3, 1, 4, 2],\n",
       " [4, 1, 2, 3],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 2, 4],\n",
       " [2, 1, 4, 3],\n",
       " [2, 1, 3, 4],\n",
       " [3, 1, 4, 2],\n",
       " [4, 1, 2, 3],\n",
       " [4, 1, 2, 3],\n",
       " [4, 1, 2, 3],\n",
       " [3, 1, 4, 2],\n",
       " [2, 1, 4, 3],\n",
       " [3, 1, 2, 4],\n",
       " [4, 1, 2, 3],\n",
       " [2, 1, 3, 4],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 2, 4],\n",
       " [4, 1, 2, 3],\n",
       " [3, 1, 4, 2],\n",
       " [4, 1, 2, 3],\n",
       " [2, 1, 3, 4],\n",
       " [4, 1, 3, 2],\n",
       " [2, 1, 3, 4],\n",
       " [2, 1, 3, 4],\n",
       " [2, 1, 4, 3],\n",
       " [4, 1, 2, 3],\n",
       " [4, 1, 2, 3],\n",
       " [3, 1, 2, 4],\n",
       " [2, 1, 3, 4],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 2, 4],\n",
       " [2, 1, 4, 3],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 2, 4],\n",
       " [2, 1, 4, 3],\n",
       " [2, 1, 3, 4],\n",
       " [4, 1, 3, 2],\n",
       " [4, 1, 2, 3],\n",
       " [2, 1, 3, 4],\n",
       " [2, 1, 4, 3],\n",
       " [3, 1, 4, 2],\n",
       " [4, 1, 3, 2],\n",
       " [2, 1, 3, 4],\n",
       " [2, 1, 3, 4],\n",
       " [4, 1, 3, 2],\n",
       " [3, 1, 4, 2],\n",
       " [3, 1, 4, 2],\n",
       " [4, 1, 3, 2],\n",
       " [3, 1, 2, 4],\n",
       " [3, 1, 4, 2],\n",
       " [4, 1, 3, 2],\n",
       " [2, 1, 4, 3],\n",
       " [3, 1, 2, 4],\n",
       " [2, 1, 3, 4],\n",
       " [2, 1, 3, 4],\n",
       " [4, 1, 3, 2],\n",
       " [2, 1, 4, 3],\n",
       " [2, 1, 3, 4],\n",
       " [4, 1, 2, 3],\n",
       " [3, 1, 4, 2]]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_ranks_filtered['model_ranks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 188)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.array(ds_ranks_filtered['model_ranks']).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import friedmanchisquare\n",
    "\n",
    "f_stat, p_value = friedmanchisquare(*np.array(ds_ranks_filtered['model_ranks']).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(340.1297872340424, 2.0454496679184383e-73)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_stat, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 3, 3, 2, 3, 2, 2, 3, 3, 3, 4, 3, 3, 4, 3, 3, 2, 3, 3, 2, 3, 4,\n",
       "        4, 4, 2, 3, 4, 2, 4, 3, 2, 4, 2, 4, 2, 2, 3, 3, 3, 4, 4, 2, 4, 4,\n",
       "        4, 2, 4, 2, 3, 3, 3, 3, 3, 3, 4, 3, 4, 4, 4, 4, 3, 3, 3, 3, 2, 2,\n",
       "        4, 3, 4, 2, 2, 4, 4, 4, 3, 3, 2, 3, 3, 4, 2, 4, 2, 3, 2, 2, 3, 2,\n",
       "        2, 4, 3, 4, 3, 2, 3, 3, 4, 3, 3, 2, 3, 4, 2, 4, 3, 3, 3, 4, 4, 3,\n",
       "        3, 3, 4, 3, 3, 3, 3, 4, 4, 3, 3, 2, 3, 2, 2, 4, 3, 4, 3, 3, 3, 2,\n",
       "        2, 3, 4, 4, 4, 3, 2, 3, 4, 2, 3, 3, 4, 3, 4, 2, 4, 2, 2, 2, 4, 4,\n",
       "        3, 2, 3, 3, 3, 2, 3, 3, 2, 2, 4, 4, 2, 2, 3, 4, 2, 2, 4, 3, 3, 4,\n",
       "        3, 3, 4, 2, 3, 2, 2, 4, 2, 2, 4, 3],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [2, 4, 4, 3, 2, 4, 4, 4, 2, 4, 3, 2, 4, 3, 2, 4, 3, 2, 4, 3, 2, 2,\n",
       "        2, 3, 3, 4, 3, 3, 3, 2, 3, 2, 3, 2, 3, 4, 4, 4, 4, 2, 3, 3, 3, 3,\n",
       "        3, 4, 2, 4, 4, 4, 4, 4, 4, 4, 2, 2, 3, 2, 2, 3, 4, 4, 4, 4, 4, 3,\n",
       "        3, 4, 3, 3, 3, 3, 3, 2, 4, 4, 4, 2, 4, 3, 3, 3, 3, 4, 4, 3, 4, 3,\n",
       "        3, 3, 4, 2, 4, 3, 2, 2, 2, 2, 2, 3, 2, 3, 4, 2, 4, 4, 4, 2, 3, 4,\n",
       "        4, 4, 2, 4, 4, 4, 4, 3, 2, 2, 4, 3, 2, 4, 4, 3, 4, 2, 4, 4, 2, 4,\n",
       "        3, 4, 2, 2, 2, 4, 4, 2, 2, 3, 4, 2, 2, 4, 2, 3, 3, 3, 3, 4, 2, 2,\n",
       "        2, 3, 4, 4, 2, 4, 4, 2, 4, 3, 3, 2, 3, 4, 4, 3, 3, 3, 3, 4, 4, 3,\n",
       "        2, 4, 3, 4, 2, 3, 3, 3, 4, 3, 2, 4],\n",
       "       [3, 2, 2, 4, 4, 3, 3, 2, 4, 2, 2, 4, 2, 2, 4, 2, 4, 4, 2, 4, 4, 3,\n",
       "        3, 2, 4, 1, 2, 4, 2, 4, 4, 3, 4, 3, 4, 3, 2, 2, 2, 3, 2, 4, 2, 2,\n",
       "        2, 3, 3, 3, 2, 2, 2, 2, 2, 2, 3, 4, 2, 3, 3, 2, 2, 2, 2, 2, 3, 4,\n",
       "        2, 2, 2, 4, 4, 2, 2, 3, 2, 2, 3, 4, 2, 2, 4, 2, 4, 2, 3, 4, 2, 4,\n",
       "        4, 2, 2, 3, 2, 4, 4, 4, 3, 4, 4, 4, 4, 2, 3, 3, 2, 2, 2, 3, 2, 2,\n",
       "        2, 2, 3, 2, 2, 2, 2, 2, 3, 4, 2, 4, 4, 3, 3, 2, 2, 3, 2, 2, 4, 3,\n",
       "        4, 2, 3, 3, 3, 2, 3, 4, 3, 4, 2, 4, 3, 2, 3, 4, 2, 4, 4, 3, 3, 3,\n",
       "        4, 4, 2, 2, 4, 3, 2, 4, 3, 4, 2, 3, 4, 3, 2, 2, 4, 4, 2, 2, 2, 2,\n",
       "        4, 2, 2, 3, 4, 4, 4, 2, 3, 4, 3, 2]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(ds_ranks_filtered['model_ranks']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt2xl_mnemonic', 'gpt3_mnemonic', 'gpt3_paragraph', 'wanikani_mnemonic']\n",
      "[3.02659574 1.00531915 3.11702128 2.85106383]\n"
     ]
    }
   ],
   "source": [
    "print(keys)\n",
    "print(np.array(ds_ranks_filtered['model_ranks']).T.mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt2xl_mnemonic', 'gpt3_mnemonic', 'gpt3_paragraph', 'wanikani_mnemonic']\n",
      "[0.760973   0.07273827 0.81025847 0.86242418]\n"
     ]
    }
   ],
   "source": [
    "print(keys)\n",
    "print(np.array(ds_ranks_filtered['model_ranks']).T.std(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<Axes: title={'center': '0'}>]], dtype=object)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(np.array(ds_ranks_filtered['model_ranks']).T[3]).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/martingrzzler___json/martingrzzler--mnemonics_benchmark-6cc75b71b93e3c15/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-19d24864971bdeff.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Component meanings: coat rack,bundle\\nKanji meaning: neglect\\nMnemonics:\\n[1] This is a coat rack that I made for my daughter's bedroom. It was bundle of neglect at first, but it turned out to be so much fun! She loves hanging her coats from the hooks and she can hang them all day long without feeling like they're falling off or getting tangled up in each other (I'm not sure if this\\n[2] Once upon a time there was a coat rack that had been neglected for many years. It was so neglected that it had become a bundle of sticks and was no longer of any use. One day, a kind-hearted soul saw the neglected coat rack and decided to take it home and give it the love and care that it deserved. With a bit of effort and a lot of love, the coat rack was restored to its former glory. From then on, it was a reminder of the importance of not neglecting the things we care about.\\n[3] I walked into the room and noticed a neglected coat rack in the corner, with a bundle of coats hanging from it. It was clear the coat rack had been forgotten, and had been neglected for some time.\\n[4] A coat rack will turn into a bundle of sticks if you neglect it. When you neglect a coat rack, the weight from the coats will pull all of the arms off, leaving it as a sparse stick. Picture this sparse, neglected coat rack. All of its arms and the coats that were on it have fallen off and are in a big pile on the ground.\\n\""
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_user_message(ds_ranks_filtered.filter(lambda x: x['model_ranks'][3] == 4)[25])['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 4, 4])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(ds_ranks_filtered['model_ranks']).T.max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def map_rank(example):\n",
    "    res = openai.ChatCompletion.create(\n",
    "        model='gpt-4',\n",
    "        messages=[character_message, get_user_message(example)],\n",
    "    )\n",
    "    example['model_answer'] = res['choices'][0]['message']['content']\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Component meanings: canopy,tree,stone\\nKanji meaning: polish\\nMnemonics:\\n[1] This is a rush transcript. Copy may not be in its final form\\n tree canopy of the stone circle at Stonehenge by polisharchitecture on Flickr, used under Creative Commons license (CC BY-NC) This interview has been edited for length and clarity The following are excerpts from an hourlong conversation between Democracy Now!'s Amy Goodman\\n[2] Once upon a time, there was a canopy of trees that stretched across the horizon. Underneath the canopy, there was a large stone. Every day, the stone was polished until it shined brightly. Eventually, it became so polished that it glistened in the sunlight beneath the canopy of trees.\\n[3] The canopy of the tree was so lush and inviting that it seemed to be calling out to me. I stepped closer and noticed a smooth stone beneath my feet, as if it had been polished by the hands of time. I looked up and marveled at the beauty of the tree, and the way the sunlight filtered through its leaves.\\n[4] Below this canopy of trees is a stone. Since it's the only stone here, you make sure to polish it. It's a single, perfectly round stone under this canopy of trees. It didn't start this way, but thanks to all the polishing you did, it has become nice and smooth.\\n\""
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_user_message(ds['train'][10])['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f45d0773069147b4838b28259b7fa60f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "The model: `gpt-4` does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-31e22ff69e03>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_rank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_answer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Dataset\"\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"self\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    526\u001b[0m         }\n\u001b[1;32m    527\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3002\u001b[0m                     \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"Map\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3003\u001b[0m                 ) as pbar:\n\u001b[0;32m-> 3004\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdataset_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3005\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3006\u001b[0m                             \u001b[0mshards_done\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3356\u001b[0m                     \u001b[0m_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3357\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshard_iterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3358\u001b[0;31m                         \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_function_on_filtered_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3359\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mupdate_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mapply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3259\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwith_rank\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3260\u001b[0m                 \u001b[0madditional_args\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3261\u001b[0;31m             \u001b[0mprocessed_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0madditional_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3262\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3263\u001b[0m                 processed_inputs = {\n",
      "\u001b[0;32m<ipython-input-137-832ca9a6657e>\u001b[0m in \u001b[0;36mmap_rank\u001b[0;34m(example)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmap_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     res = openai.ChatCompletion.create(\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gpt-4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcharacter_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_user_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         )\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m             return (\n\u001b[0;32m--> 620\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    621\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    684\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m             )\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: The model: `gpt-4` does not exist"
     ]
    }
   ],
   "source": [
    "ds['train'].select(range(1)).map(map_rank)['model_answer']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are a human that rank orders mnemonics. The mnemonics have been constructed to help students learn Japanese Kanji and are based on its component meanings such that the Kanji meaning can be recalled easily. You are given four different mnemonics and you have to order them from most memorable to least memorable.\n",
    "Output the ordered numbers separated by commas. E.g. 4,2,1,3\n",
    "\n",
    "\n",
    "Component meanings: moon,power\\nKanji meaning: armpit\\nMnemonics:\\n\n",
    "[1] It's been armpit time for a while now, but moon power has finally arrived in the form of solar panels that can be installed on your home or business. The technology is called photovoltaics (PV), and it works by harnessing sunlight to generate electricity from light-emitting diodes known as PV cells\\n\n",
    "[2] Once upon a time there was a man who lived on the moon. He was so powerful that he could lift a car with one arm. He was so strong that his armpit could hold the weight of a small planet. He used his moon powers to help people in need and the people of the moon were grateful.\\n\n",
    "[3] The moon has a mysterious power that can be felt in the armpit of the night. As we gaze upon its beauty, we can't help but feel a sense of awe and wonder. The moon has an undeniable power that can be seen in its ability to light up the darkness and bring us peace.\\n\n",
    "[4] The moon has a lot of power that is power it gets from the power of every armpit of every human on earth! Why does your armpit smell? It’s because the moon is draining the power from your armpit. The moon saps power from your armpit and that power is sucked up into the sky where the moon collects the power for its own devices. Imagine an aura of stinky power traveling from your armpit to the moon. Feel the power leaving you as the moon saps your power through your armpits.\\n\n",
    "\n",
    "\n",
    "Based on my analysis of the given mnemonics, the ordered numbers from most memorable to least memorable are: 2, 3, 1, 4.\n",
    "\n",
    "Here's why I think so:\n",
    "\n",
    "Mnemonic [2] personifies the Kanji by creating a story of a powerful man living on the moon, whose armpit is strong enough to hold a planet. This creates a vivid and engaging image that's easy to remember, making it the most memorable of the four.\n",
    "\n",
    "Mnemonic [3] also makes use of imagery and connects the power of the moon with the feeling in one's armpit at night. This association is unique and interesting, making it the second most memorable mnemonic.\n",
    "\n",
    "Mnemonic [1] explains the meaning of the Kanji using technical terminology, photovoltaics, which may be difficult for some students to remember. However, it does create a clear and logical connection between the Kanji meaning and the component meanings of moon and power. This makes it the third most memorable mnemonic.\n",
    "\n",
    "Mnemonic [4] connects the moon's power with the smell of one's armpit, which may not be the most appealing association. Additionally, the explanation provided for the Kanji meaning is not as clear or memorable as the other mnemonics. Therefore, it's the least memorable of the four.\n",
    "\n",
    "GPT 4\n",
    "\n",
    "[2] Ranked 1st: This mnemonic creates a vivid and engaging story about a man who lived on the moon with incredible power. It directly relates the component meanings (moon and power) to the Kanji meaning (armpit) by stating that the man's armpit could hold the weight of a small planet. The imagery of the man's strength and the connection to the moon make this mnemonic memorable.\n",
    "\n",
    "[3] Ranked 2nd: This mnemonic ties the component meanings to the Kanji meaning by using poetic language and creating an atmosphere of awe and wonder. It describes the moon's power as something that can be felt in the \"armpit of the night,\" making the connection to the Kanji meaning. While it may not be as striking as the story in mnemonic 2, it is still memorable because of its poetic nature.\n",
    "\n",
    "[4] Ranked 3rd: This mnemonic takes a humorous approach, suggesting that the moon draws its power from the armpits of humans on Earth. The concept of \"stinky power\" being sapped from one's armpit creates a quirky image that can help with memorization. However, the direct connection between the component meanings and the Kanji meaning is not as strong as in the first two mnemonics.\n",
    "\n",
    "[1] Ranked 4th: This mnemonic primarily focuses on solar panels and photovoltaics, which are unrelated to the Kanji meaning (armpit) and the component meanings (moon, power). The phrase \"armpit time\" is used, but it does not make a strong connection between the component meanings and the Kanji meaning. As a result, this mnemonic is the least memorable of the four."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A blue horse horse nsubj took\n",
      "his gun gun dobj took\n",
      "the bank official official pobj at\n",
      "['A blue horse', 'his gun', 'the bank official']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "def extract_noun_phrases(sentence):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(sentence)\n",
    "    noun_phrases = [chunk.text for chunk in doc.noun_chunks]\n",
    "    for c in doc.noun_chunks:\n",
    "        print(c.text, c.root.text, c.root.dep_, c.root.head.text)\n",
    "    return noun_phrases\n",
    "\n",
    "sentence = \"A blue horse took his gun and shot at the bank official\"\n",
    "noun_phrases = extract_noun_phrases(sentence)\n",
    "print(noun_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['horse', 'gun', 'shot', 'bank', 'official']\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "def extract_phrases_nltk(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "\n",
    "    phrases = []\n",
    "    current_phrase = []\n",
    "\n",
    "    for i, (word, pos) in enumerate(tagged_tokens):\n",
    "        current_phrase.append(word)\n",
    "        \n",
    "        # Check if the current word is a noun\n",
    "        if pos.startswith(\"NN\"):\n",
    "            # Check if the previous word is a verb\n",
    "            if i > 0 and tagged_tokens[i - 1][1].startswith(\"VB\"):\n",
    "                phrases.append(' '.join(current_phrase[-2:]))\n",
    "            else:\n",
    "                phrases.append(word)\n",
    "\n",
    "            current_phrase = []\n",
    "\n",
    "    return phrases\n",
    "\n",
    "sentence = \"A blue horse took his gun and shot at the bank official\"\n",
    "phrases = extract_phrases_nltk(sentence)\n",
    "print(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['horse took A blue horse', 'horse took his gun', 'the bank official']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "def extract_phrases(sentence):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(sentence)\n",
    "\n",
    "    \n",
    "    phrases = []\n",
    "    for chunk in doc.noun_chunks:\n",
    "        # Check if the root of the noun chunk has a left sibling that is a verb\n",
    "        left_sibling = chunk.root.head\n",
    "        if left_sibling.dep_ == 'ROOT' or left_sibling.pos_ == 'VERB':\n",
    "            # Combine the verb and its associated words with the noun chunk\n",
    "            combined_phrase = ' '.join([t.text for t in left_sibling.lefts] + [left_sibling.text] + [chunk.text])\n",
    "            phrases.append(combined_phrase)\n",
    "        else:\n",
    "            phrases.append(chunk.text)\n",
    "\n",
    "    return phrases\n",
    "\n",
    "sentence = \"A blue horse took his gun and shot at the bank official\"\n",
    "phrases = extract_phrases(sentence)\n",
    "print(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonomous cars cars nsubj shift\n",
      "insurance liability liability dobj shift\n",
      "manufacturers manufacturers pobj toward\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Autonomous cars shift insurance liability toward manufacturers\")\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text, chunk.root.text, chunk.root.dep_,\n",
    "            chunk.root.head.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
